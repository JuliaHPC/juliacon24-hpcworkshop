{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **What are threads?**\n",
    "\n",
    "* **How many threads are there?**\n",
    "\n",
    "* **Where are the threads running?**\n",
    "\n",
    "* **How do I use the threads?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are threads?\n",
    "Threads are **execution units within a process** that can run simultaneously and **share memory** (heap).\n",
    "\n",
    "<br>\n",
    "<img src=\"./imgs/stack_heap_threads.svg\" width=450px>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many threads are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia starts with a single *user thread*. We must tell it explicitly to start multiple user threads.\n",
    "\n",
    "* Environment variable: `JULIA_NUM_THREADS=4`\n",
    "* Command line argument: `julia -t 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is currently not (really) possible to change the number of threads at runtime!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are the threads running?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ThreadPinning.jl](https://github.com/carstenbauer/ThreadPinning.jl) is the tool for visualizing and controlling thread placement in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ThreadPinning\n",
    "\n",
    "threadinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinning threads (i.e. controling where they are running)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To avoid double occupancy of CPU cores.\n",
    "* To reduce noise in benchmarks.\n",
    "* To address the complexity of the system topology, e.g. to use specific/all memory domains (NUMA).\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pinthreads(strategy)`\n",
    "* `:cputhreads` pin to CPU threads (incl. \"hypterthreads\") one after another\n",
    "* `:cores:` pin to CPU cores one after another\n",
    "* `:numa:` alternate between NUMA domains (round-robin)\n",
    "* `:sockets:` alternate between sockets (round-robin)\n",
    "* `:affinitymask`: pin according to an external affinity mask (e.g. set by SLURM)\n",
    "\n",
    "(More? See my talk at JuliaCon2023 @ MIT: https://youtu.be/6Whc9XtlCC0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinthreads(:cores) # try :cores or :sockets or :numa or :random or :affinitymask\n",
    "# threadinfo(; slurm=true)\n",
    "threadinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory domains (NUMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/amd_milan_cpu_die.svg\" width=800px>\n",
    "\n",
    "**Image source:** [AMD, High Performance Computing (HPC) Tuning Guide for AMD EPYCTM 7003 Series Processors](https://www.amd.com/system/files/documents/high-performance-computing-tuning-guide-amd-epyc7003-series-processors.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinthreads(:numa)\n",
    "threadinfo(; groupby=:numa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Hwloc\n",
    "# topology_graphical()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I use the threads?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-based multithreading\n",
    "\n",
    "In traditional HPC, one typically tells each thread what to do. **(\"One thinks about threads\")**\n",
    "\n",
    "Julia implements **task-based multithreading**. In this paradigm, a task - e.g. a computational piece of a code - is marked for **parallel** execution on **any** of the available Julia threads. Julia's **dynamic scheduler** will automatically put the task on one of the threads and trigger the execution of the task on said thread.\n",
    "\n",
    "<br>\n",
    "<img src=\"./imgs/tasks_threads_cores.svg\" width=750px>\n",
    "</br>\n",
    "\n",
    "Generally speaking, the user should **think about tasks and not threads**.\n",
    "* The scheduler is controlling on which thread a task will eventually run.\n",
    "* It might even dynamically [migrate tasks](https://docs.julialang.org/en/v1/manual/multi-threading/#man-task-migration) between threads.\n",
    "\n",
    "**Advantages:**\n",
    "* high-level abstraction\n",
    "* nestability / composability (especially important for libraries)\n",
    "\n",
    "**Disadvantages:**\n",
    "* scheduling overhead\n",
    "* uncertain and potentially suboptimal task ‚Üí thread assignment\n",
    "  * **can get in the way when performance engineering** because\n",
    "    * scheduler has limited information (e.g. about the system topology)\n",
    "    * profiling tools often don't know anything about tasks but monitor threads (or even CPU-cores) instead (e.g. LIKWID)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `@threads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Splits up the iteration space into `nthreads()` contiguous chunks**\n",
    "* Creates a task for each of them and hands them off to the dynamic scheduler (essentially `@spawn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Threads: @threads, threadid, nthreads\n",
    "using ThreadPinning: taskid # for pedagogical purposes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates nthreads() many tasks\n",
    "\n",
    "@threads for i in 1:2*nthreads()\n",
    "    println(\"Task \", ThreadPinning.taskid(), \" is running iteration \", i, \" on thread \", threadid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Static scheduling: `@threads :static`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `@threads` there is the `:static` scheduling option to opt-out of Julia's dynamic scheduling.\n",
    "\n",
    "Syntax: `@threads :static for ...`\n",
    "\n",
    " * **statically** maps tasks/chunks to threads, specifically: task 1 ‚Üí thread 1, task 2 ‚Üí thread 2, and so on.\n",
    "   * no task migration, i.e. **fixed task-thread mapping** üëç\n",
    "   * only little overhead üëç\n",
    "   * not composable / nestable üëé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@threads :static for i in 1:2*nthreads()\n",
    "    println(\"Task \", taskid(), \" is running iteration \", i, \" on thread \", threadid());\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `@threads :static`, every thread handles precisely two iterations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If time permits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *User threads* vs other threads\n",
    "\n",
    "The Julia process is also spawning multiple threads already in \"single-threaded\" mode, like\n",
    "* a thread for unix signal listening\n",
    "* GC threads\n",
    "* multiple **OpenBLAS threads** for BLAS/LAPACK operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "BLAS.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garbage collection\n",
    "\n",
    "If it gets triggered, it stops the world (all threads) for clearing up memory.\n",
    "\n",
    "Hence, when using multithreading, it is very important to **avoid heap allocations!**\n",
    "\n",
    "(If you can't avoid allocations, consider using multiprocessing instead.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
